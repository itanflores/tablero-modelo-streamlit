import streamlit as st
import pandas as pd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import requests
import io

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="Tablero de EvaluaciÃ³n", page_icon="ğŸ“Š", layout="wide")

# ğŸ“Œ TÃ­tulo
st.title("ğŸ“Š Tablero de EvaluaciÃ³n del Modelo de ClasificaciÃ³n")

# Cargar Dataset
GITHUB_API_URL = "https://github.com/itanflores/tablero-modelo-streamlit/raw/main/dataset_monitoreo_servers.csv"
response = requests.get(GITHUB_API_URL, stream=True)

if response.status_code == 200:
    df = pd.read_csv(io.BytesIO(response.content), encoding="utf-8")
else:
    st.error("âŒ Error al descargar el dataset.")
    st.stop()

df.columns = df.columns.str.strip()

# Verificar columna objetivo
if "Estado del Sistema" in df.columns:
    df['Estado del Sistema Codificado'] = df['Estado del Sistema'].map({"Inactivo": 0, "Normal": 1, "Advertencia": 2, "CrÃ­tico": 3})
else:
    st.error("âŒ Error: La columna 'Estado del Sistema' no se encuentra.")
    st.stop()

# Preprocesamiento
X = df.drop(["Estado del Sistema", "Estado del Sistema Codificado"], axis=1)
y = df["Estado del Sistema Codificado"]
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Entrenamiento del modelo
model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# ğŸ“Œ **SecciÃ³n 1: EvaluaciÃ³n General del Modelo**
st.header("ğŸ“Œ EvaluaciÃ³n General del Modelo")

col1, col2, col3 = st.columns([1.5, 2, 2])

with col1:
    st.metric("ğŸ“Š PrecisiÃ³n del Modelo", f"{accuracy_score(y_test, y_pred):.4f}")
    st.caption("ğŸ”¹ La precisiÃ³n mide la proporciÃ³n de predicciones correctas. Valores mÃ¡s altos indican mejor desempeÃ±o.")

with col2.expander("ğŸ“‹ Reporte de ClasificaciÃ³n"):
    st.text(classification_report(y_test, y_pred))
    st.caption("ğŸ”¹ El reporte muestra mÃ©tricas clave como precisiÃ³n, recall y F1-score para evaluar el desempeÃ±o en cada categorÃ­a.")

with col3:
    st.write("ğŸ“Š Matriz de ConfusiÃ³n")
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues")
    st.pyplot(fig)
    st.caption("ğŸ”¹ La matriz de confusiÃ³n muestra las predicciones correctas en la diagonal y los errores fuera de ella.")

st.divider()

# ğŸ“Œ **SecciÃ³n 2: Importancia de Variables**
st.header("ğŸ“Š Importancia de Variables en la PredicciÃ³n")

df_importance = pd.DataFrame({
    "Variable": X.columns,
    "Importancia": model.feature_importances_
}).sort_values(by="Importancia", ascending=False)

col4, col5 = st.columns([1.5, 3])

with col4.expander("ğŸ“‹ Ver Variables Importantes", expanded=True):
    st.dataframe(df_importance.head(10), height=300)
    st.caption("ğŸ”¹ Muestra las 10 variables mÃ¡s importantes utilizadas por el modelo para la toma de decisiones.")

fig_imp = px.bar(df_importance.head(10), 
                 x="Importancia", 
                 y="Variable", 
                 orientation='h', 
                 title="ğŸ“Š Importancia de Variables")

col5.plotly_chart(fig_imp, use_container_width=True)
st.caption("ğŸ”¹ Este grÃ¡fico destaca quÃ© variables tienen mayor peso en las predicciones del modelo.")

st.divider()

# ğŸ“Œ **SecciÃ³n 3: ComparaciÃ³n de Modelos**
st.header("ğŸ“Š ComparaciÃ³n de Modelos de ClasificaciÃ³n")

# ğŸ”¹ PestaÃ±as para organizar cada modelo
tab1, tab2, tab3 = st.tabs(["ğŸŒ³ Ãrbol de DecisiÃ³n", "ğŸ“ˆ RegresiÃ³n LogÃ­stica", "ğŸŒ² Random Forest"])

# ğŸ“Œ SecciÃ³n Ãrbol de DecisiÃ³n en `st.tabs()`
with tab1:
    st.subheader("ğŸŒ³ Ãrbol de DecisiÃ³n")
    st.caption("ğŸ”¹ Modelo basado en reglas jerÃ¡rquicas. Es fÃ¡cil de interpretar pero puede sobreajustarse con demasiada profundidad.")

    if "tree_trained" not in st.session_state:
        st.session_state["tree_trained"] = False

    if st.button("Entrenar Ãrbol de DecisiÃ³n"):
        with st.spinner("Entrenando..."):
            from sklearn.tree import DecisionTreeClassifier
            tree_clf = DecisionTreeClassifier(max_depth=5)
            tree_clf.fit(X_train, y_train)
            st.session_state["tree_acc"] = accuracy_score(y_test, tree_clf.predict(X_test))
            st.session_state["tree_cm"] = confusion_matrix(y_test, tree_clf.predict(X_test))
            st.session_state["tree_trained"] = True  

    if st.session_state["tree_trained"]:
        st.metric("PrecisiÃ³n", f"{st.session_state['tree_acc']:.4f}")

# ğŸ“ˆ **RegresiÃ³n LogÃ­stica**
with tab2:
    st.subheader("ğŸ“ˆ RegresiÃ³n LogÃ­stica")
    st.caption("ğŸ”¹ Modelo lineal utilizado para clasificaciones binarias o multiclase con buena interpretabilidad.")

    if st.button("Entrenar RegresiÃ³n LogÃ­stica"):
        with st.spinner("Entrenando..."):
            from sklearn.linear_model import LogisticRegression
            log_clf = LogisticRegression(max_iter=200)
            log_clf.fit(X_train, y_train)
            acc_log = accuracy_score(y_test, log_clf.predict(X_test))
            st.metric("PrecisiÃ³n", f"{acc_log:.4f}")

            # ğŸ“Š Mostrar matriz de confusiÃ³n
            fig, ax = plt.subplots(figsize=(5, 4))
            sns.heatmap(confusion_matrix(y_test, log_clf.predict(X_test)), annot=True, fmt="d", cmap="Blues")
            st.pyplot(fig)
            st.caption("ğŸ”¹ La matriz de confusiÃ³n evalÃºa quÃ© tan bien el modelo distingue entre clases.")

# ğŸŒ² **Random Forest**
with tab3:
    st.subheader("ğŸŒ² Random Forest")
    st.caption("ğŸ”¹ Conjunto de mÃºltiples Ã¡rboles de decisiÃ³n que mejora la precisiÃ³n y reduce el sobreajuste.")

    if st.button("Entrenar Random Forest"):
        with st.spinner("Entrenando..."):
            forest_clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1)
            forest_clf.fit(X_train, y_train)
            acc_forest = accuracy_score(y_test, forest_clf.predict(X_test))
            st.metric("PrecisiÃ³n", f"{acc_forest:.4f}")

            # ğŸ“Š Mostrar matriz de confusiÃ³n
            fig, ax = plt.subplots(figsize=(5, 4))
            sns.heatmap(confusion_matrix(y_test, forest_clf.predict(X_test)), annot=True, fmt="d", cmap="Blues")
            st.pyplot(fig)
            st.caption("ğŸ”¹ EvalÃºa los aciertos y errores del modelo en la clasificaciÃ³n.")

