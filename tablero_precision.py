import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from io import StringIO
from google.cloud import storage
from sklearn.preprocessing import MinMaxScaler  # âœ… Importado correctamente
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ğŸ“Œ ConfiguraciÃ³n del Cliente de Google Cloud Storage (Solo se mantiene una vez)
BUCKET_NAME = "monitoreo_gcp_bucket"
ARCHIVO_DATOS = "dataset_monitoreo_servers.csv"
ARCHIVO_PROCESADO = "dataset_procesado.csv"

# Inicializar cliente de Google Cloud Storage
storage_client = storage.Client()
bucket = storage_client.bucket(BUCKET_NAME)

# ğŸ“Œ FunciÃ³n para cargar los datos desde GCP Storage
@st.cache_data
def cargar_datos():
    try:
        blob = bucket.blob(ARCHIVO_DATOS)
        contenido = blob.download_as_text()
        df = pd.read_csv(StringIO(contenido))
        return df
    except Exception as e:
        st.error(f"âŒ Error al descargar el archivo desde GCP: {e}")
        return None

df = cargar_datos()
if df is None:
    st.stop()

# ğŸ“Œ Preprocesamiento de Datos
df["Fecha"] = pd.to_datetime(df["Fecha"], errors="coerce")
df.drop_duplicates(inplace=True)
df.dropna(inplace=True)

# CodificaciÃ³n ordinal para "Estado del Sistema"
estado_mapping = {"Inactivo": 0, "Normal": 1, "Advertencia": 2, "CrÃ­tico": 3}
df["Estado del Sistema Codificado"] = df["Estado del Sistema"].map(estado_mapping)

# CodificaciÃ³n one-hot para "Tipo de Servidor"
df = pd.get_dummies(df, columns=["Tipo de Servidor"], prefix="Servidor", drop_first=True)

# NormalizaciÃ³n de mÃ©tricas continuas
scaler = MinMaxScaler()
metricas_continuas = ["Uso CPU (%)", "Temperatura (Â°C)", "Carga de Red (MB/s)", "Latencia Red (ms)"]
df[metricas_continuas] = scaler.fit_transform(df[metricas_continuas])

# ğŸ“Œ DivisiÃ³n en conjunto de entrenamiento y prueba
X = df.drop(["Estado del Sistema", "Estado del Sistema Codificado", "Fecha", "Hostname"], axis=1, errors="ignore")
y = df["Estado del Sistema Codificado"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# ğŸ“Œ Entrenamiento del Modelo Random Forest
rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

# ğŸ“Œ PredicciÃ³n y EvaluaciÃ³n del Modelo
y_pred = rf_model.predict(X_test)
precision_modelo = accuracy_score(y_test, y_pred)

# ğŸ“Œ VisualizaciÃ³n en Streamlit
st.title("ğŸ“Š Monitoreo de Servidores - GCP")

st.sidebar.header("Filtros")
estados_seleccionados = st.sidebar.multiselect("Selecciona Estados:", df["Estado del Sistema"].unique(), default=df["Estado del Sistema"].unique())
df_filtrado = df[df["Estado del Sistema"].isin(estados_seleccionados)]

if df_filtrado.empty:
    st.warning("âš  No hay datos disponibles con los filtros seleccionados.")
    st.stop()

# ğŸ“Œ GrÃ¡ficos en Streamlit
st.subheader("ğŸ“ˆ EvoluciÃ³n del Estado del Sistema")
df_grouped = df_filtrado.groupby(["Fecha", "Estado del Sistema"]).size().reset_index(name="Cantidad")
st.line_chart(df_grouped.pivot(index="Fecha", columns="Estado del Sistema", values="Cantidad").fillna(0))

st.subheader("ğŸŒ¡ DistribuciÃ³n de Temperatura por Estado")
fig, ax = plt.subplots(figsize=(8, 6))
sns.boxplot(x=df["Estado del Sistema"], y=df["Temperatura (Â°C)"], ax=ax)
st.pyplot(fig)

st.subheader("ğŸ“Š Importancia de Variables en el Modelo")
feature_importances = pd.DataFrame({"Variable": X_train.columns, "Importancia": rf_model.feature_importances_}).sort_values(by="Importancia", ascending=False)
st.bar_chart(feature_importances.set_index("Variable"))

st.subheader("âœ… PrecisiÃ³n del Modelo")
st.metric(label="PrecisiÃ³n del Modelo Random Forest", value=f"{precision_modelo:.2%}")

# ğŸ“Œ SECCIÃ“N DE COMPARACIÃ“N DE MODELOS (se mantiene igual)
st.header("ğŸ“Š ComparaciÃ³n de Modelos de ClasificaciÃ³n")

tab1, tab2, tab3 = st.tabs(["ğŸŒ³ Ãrbol de DecisiÃ³n", "ğŸ“ˆ RegresiÃ³n LogÃ­stica", "ğŸŒ² Random Forest"])

with tab1:
    st.subheader("ğŸŒ³ Ãrbol de DecisiÃ³n")
    if st.button("Entrenar Ãrbol de DecisiÃ³n"):
        from sklearn.tree import DecisionTreeClassifier
        tree_clf = DecisionTreeClassifier(max_depth=5)
        tree_clf.fit(X_train, y_train)
        acc_tree = accuracy_score(y_test, tree_clf.predict(X_test))
        st.metric("PrecisiÃ³n", f"{acc_tree:.4f}")

with tab2:
    st.subheader("ğŸ“ˆ RegresiÃ³n LogÃ­stica")
    if st.button("Entrenar RegresiÃ³n LogÃ­stica"):
        from sklearn.linear_model import LogisticRegression
        log_clf = LogisticRegression(max_iter=50, n_jobs=-1)
        log_clf.fit(X_train, y_train)
        acc_log = accuracy_score(y_test, log_clf.predict(X_test))
        st.metric("PrecisiÃ³n", f"{acc_log:.4f}")

with tab3:
    st.subheader("ğŸŒ² Random Forest")
    if st.button("Entrenar Random Forest"):
        forest_clf = RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42)
        forest_clf.fit(X_train, y_train)
        acc_forest = accuracy_score(y_test, forest_clf.predict(X_test))
        st.metric("PrecisiÃ³n", f"{acc_forest:.4f}")

# ğŸ“Œ NUEVA SECCIÃ“N: PROCESAMIENTO Y EXPORTACIÃ“N DE DATOS A GCP
if "datos_procesados" not in st.session_state:
    st.session_state["datos_procesados"] = pd.DataFrame()

if st.button("âš™ï¸ Procesar Datos"):
    df_procesado = df.copy()
    st.session_state["datos_procesados"] = df_procesado
    st.success("âœ… Datos procesados correctamente.")

if not st.session_state["datos_procesados"].empty:
    def exportar_datos():
        try:
            df_procesado = st.session_state["datos_procesados"]
            blob_procesado = bucket.blob(ARCHIVO_PROCESADO)
            blob_procesado.upload_from_string(df_procesado.to_csv(index=False), content_type="text/csv")
            st.success(f"âœ… Datos procesados exportados a {BUCKET_NAME}/{ARCHIVO_PROCESADO}")
        except Exception as e:
            st.error(f"âŒ Error al exportar datos a GCP: {e}")

    if st.button("ğŸ“¤ Guardar Datos Procesados en GCP"):
        exportar_datos()
